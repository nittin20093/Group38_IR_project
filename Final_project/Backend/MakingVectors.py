# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pD23q-cz1MMkTmJwhaXwPn8OFXWwcm-P
"""

# pip install annoy

# # from google.colab import drive
# # drive.mount('/content/drive')

# pip install scikit-learn

# pip install tensorflow tensorflow_hub matplotlib numpy pandas pickle

import numpy as np
import pickle
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import tensorflow_hub as hub
import functools
import os, os.path
import urllib.request
from PIL import Image
from sklearn.neighbors import NearestNeighbors
from annoy import AnnoyIndex


# BATCH_SIZE = 32
# IMG_WIDTH = IMG_HEIGHT = 256



allImagesvector=[]


vectorizer = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/5", trainable=False)
])
vectorizer.build([None, 1024, 1024, 3])





def preprocess_image(image):
    image = tf.image.resize_with_crop_or_pad(image, target_height=256, target_width=256)
    image = tf.cast(image, tf.float32) / 255.0
    return image




# features = vectorizer.predict(images, batch_size=BATCH_SIZE)
# print(features.shape)




# def DownloadImageIfNot():



def getallImagelink(filepath):
  image_links={}
  count=0
  file = open(filepath,"r")
  for hotel in file:
      # print(hotel)
      if(count==0):
        count=count+1
        continue
      pa="img_link"
      pathend='room_size'
      comma=hotel.index(',')
      index=hotel[:comma]
      x=hotel.index(pa) + 12
      y=hotel.index(pathend)-4
      imglink=hotel[x:y]

      # imglink=
      image_links[count-1]=imglink
      count=count+1
  file.close
  return image_links

def DownloadImagesVectors(allImageslink):
  Images_vectors={}
  count=0
  for i,j in allImageslink.items():
    path="./home/photo"
    try:
        urllib.request.urlretrieve(j,path)
    except:
        continue
    img = tf.io.read_file(path)

    img = tf.io.decode_jpeg(img, channels=3)

    img = tf.image.resize_with_pad(img, 256, 256)

    img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]

    features = vectorizer.predict(img)
    # print(features)
    print(len(features[0]))
    Images_vectors[i]=features
    allImagesvector.append(features[0])
  return Images_vectors


url="https://leverageedublog.s3.ap-south-1.amazonaws.com/blog/wp-content/uploads/2020/03/24185535/Online-Learning.jpg"



Filepath="./home/banglore_hotels_details_final_freq.csv"
imagelinks=getallImagelink(Filepath)


ImageVectors=DownloadImagesVectors(imagelinks)
# print(ImageVectors)

dbfile = open('./home/banglore_dataset', 'ab')
      
pickle.dump(ImageVectors, dbfile)                     
dbfile.close()
